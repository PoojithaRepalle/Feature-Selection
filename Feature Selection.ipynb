{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mffnRnGceFrD",
        "outputId": "6b6c6bb2-2eea-4f05-82a6-06e5d91e8f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after Missing Value Filter (Diabetes): 0.7359\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import VarianceThreshold, RFECV\n",
        "from sklearn.metrics import accuracy_score\n",
        "diabetes_df = pd.read_csv('/content/sample_data/diabetes.csv')\n",
        "\n",
        "\n",
        "missing_values = diabetes_df.isnull().mean()\n",
        "diabetes_filtered = diabetes_df.loc[:, missing_values < 0.3]\n",
        "\n",
        "\n",
        "X = diabetes_filtered.drop(columns=['Outcome'])\n",
        "y = diabetes_filtered['Outcome']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "logistic_model = LogisticRegression(max_iter=200)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy after Missing Value Filter (Diabetes): {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = diabetes_filtered.corr()\n",
        "\n",
        "high_corr_pairs = corr_matrix[corr_matrix.abs() > 0.8].stack().index.tolist()\n",
        "\n",
        "\n",
        "cols_to_drop = set()\n",
        "\n",
        "\n",
        "for col1, col2 in high_corr_pairs:\n",
        "    if col1 != col2:\n",
        "        cols_to_drop.add(col2)\n",
        "\n",
        "diabetes_filtered_corr = diabetes_filtered.drop(columns=cols_to_drop)\n",
        "\n",
        "X_corr = diabetes_filtered_corr.drop(columns=['Outcome'])\n",
        "y_corr = diabetes_filtered_corr['Outcome']\n",
        "\n",
        "X_train_corr, X_test_corr, y_train_corr, y_test_corr = train_test_split(X_corr, y_corr, test_size=0.3, random_state=42)\n",
        "\n",
        "logistic_model_corr = LogisticRegression(max_iter=200)\n",
        "logistic_model_corr.fit(X_train_corr, y_train_corr)\n",
        "\n",
        "y_pred_corr = logistic_model_corr.predict(X_test_corr)\n",
        "\n",
        "accuracy_corr = accuracy_score(y_test_corr, y_pred_corr)\n",
        "print(f'Accuracy after High Correlation Filter (Diabetes): {accuracy_corr:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNGXMLwufil5",
        "outputId": "bc319992-5dc9-4358-8b59-0ebafe2aa3cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after High Correlation Filter (Diabetes): 0.7359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "rfecv_selector = RFECV(estimator=LogisticRegression(max_iter=200), step=1, cv=5)\n",
        "rfecv_selector.fit(X, y)\n",
        "\n",
        "\n",
        "X_train_selected, X_test_selected, y_train_selected, y_test_selected = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
        "\n",
        "logistic_model_selected = LogisticRegression(max_iter=200)\n",
        "logistic_model_selected.fit(X_train_selected, y_train_selected)\n",
        "\n",
        "y_pred_selected = logistic_model_selected.predict(X_test_selected)\n",
        "\n",
        "accuracy_selected = accuracy_score(y_test_selected, y_pred_selected)\n",
        "print(f'Accuracy after Forward Feature Selection (Diabetes): {accuracy_selected:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4DFtMMSf1nM",
        "outputId": "cfc8b4ef-cd48-4bb5-cef5-d681ed512c9e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after Forward Feature Selection (Diabetes): 0.7359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "\n",
        "decision_tree_model = DecisionTreeClassifier()\n",
        "\n",
        "decision_tree_model.fit(X_train, y_train)\n",
        "\n",
        "feature_importances = decision_tree_model.feature_importances_\n",
        "sorted_indices = np.argsort(feature_importances)\n",
        "\n",
        "remaining_features = list(X.columns)\n",
        "print(f\"Initial Number of Features: {len(remaining_features)}\")\n",
        "\n",
        "while len(remaining_features) > 5:\n",
        "\n",
        "    least_important_feature_index = sorted_indices[0]\n",
        "    feature_to_drop = remaining_features[least_important_feature_index]\n",
        "\n",
        "    X = X.drop(columns=[feature_to_drop])\n",
        "    remaining_features.remove(feature_to_drop)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    decision_tree_model.fit(X_train, y_train)\n",
        "\n",
        "    feature_importances = decision_tree_model.feature_importances_\n",
        "    sorted_indices = np.argsort(feature_importances)\n",
        "\n",
        "print(f\"Final Number of Features After Elimination: {len(remaining_features)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axnUvi2Pg5Kj",
        "outputId": "332c8f6f-e587-44e2-eb30-f765102b2829"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Number of Features: 5\n",
            "Final Number of Features After Elimination: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sorted_importance_indices = np.argsort(feature_importances)[::-1]\n",
        "\n",
        "num_features_to_display = min(5, len(remaining_features))\n",
        "\n",
        "print(\"Top Important Features:\")\n",
        "\n",
        "for i in range(num_features_to_display):\n",
        "    if i < len(feature_importances):\n",
        "        feature_name = remaining_features[sorted_importance_indices[i]]\n",
        "        importance_value = feature_importances[sorted_importance_indices[i]]\n",
        "        print(f\"{i + 1}. Feature '{feature_name}': {importance_value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4LAlUGGhMcm",
        "outputId": "f60681ff-9785-4fd8-fb94-458765196f79"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Important Features:\n",
            "1. Feature 'Glucose': 0.3619\n",
            "2. Feature 'BMI': 0.2167\n",
            "3. Feature 'DiabetesPedigreeFunction': 0.1719\n",
            "4. Feature 'Age': 0.1658\n",
            "5. Feature 'BloodPressure': 0.0838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import VarianceThreshold, RFE, SelectFromModel\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "housing_data = pd.read_csv('/content/sample_data/melbourne_housing_raw.csv')\n",
        "\n",
        "missing_pct = housing_data.isnull().mean() * 100\n",
        "cols_to_remove = [col for col in missing_pct.index if missing_pct[col] > 20 and col != 'Price']\n",
        "cleaned_data = housing_data.drop(columns=cols_to_remove)\n",
        "cleaned_data = cleaned_data.dropna(subset=['Price'])\n",
        "\n",
        "X = cleaned_data.drop(columns=['Price', 'Date', 'Suburb', 'Type', 'Method', 'SellerG', 'CouncilArea', 'Regionname'])\n",
        "y = cleaned_data['Price']\n",
        "\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "corr_matrix = X_train.corr().abs()\n",
        "high_corr_pairs = np.where(corr_matrix > 0.85)\n",
        "high_corr_features = set([X_train.columns[i] for i in high_corr_pairs[0] if i != high_corr_pairs[1][i]])\n",
        "\n",
        "X_train_corr_filtered = X_train.drop(columns=high_corr_features)\n",
        "X_test_corr_filtered = X_test.drop(columns=high_corr_features)\n",
        "\n",
        "variance_filter = VarianceThreshold(threshold=0.01)\n",
        "X_train_low_var = variance_filter.fit_transform(X_train_corr_filtered)\n",
        "X_test_low_var = variance_filter.transform(X_test_corr_filtered)\n",
        "\n",
        "linear_reg_model = LinearRegression()\n",
        "rfe_forward_selector = RFE(estimator=linear_reg_model, n_features_to_select=5, step=1)\n",
        "rfe_forward_selector.fit(X_train_low_var, y_train)\n",
        "X_train_forward_selected = rfe_forward_selector.transform(X_train_low_var)\n",
        "X_test_forward_selected = rfe_forward_selector.transform(X_test_low_var)\n",
        "\n",
        "rf_model_backward = RandomForestRegressor(random_state=42)\n",
        "rfe_backward_selector = RFE(estimator=rf_model_backward, n_features_to_select=5, step=1)\n",
        "rfe_backward_selector.fit(X_train_low_var, y_train)\n",
        "X_train_backward_selected = rfe_backward_selector.transform(X_train_low_var)\n",
        "X_test_backward_selected = rfe_backward_selector.transform(X_test_low_var)\n",
        "\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "important_feature_selector = SelectFromModel(rf_model, threshold=\"mean\", prefit=True)\n",
        "X_train_rf_selected = important_feature_selector.transform(X_train)\n",
        "X_test_rf_selected = important_feature_selector.transform(X_test)\n",
        "\n",
        "def evaluate_model(X_train, X_test, y_train, y_test):\n",
        "    model = RandomForestRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    return mse\n",
        "\n",
        "results = {\n",
        "    \"Baseline (No Feature Selection)\": evaluate_model(X_train, X_test, y_train, y_test),\n",
        "    \"High Correlation Filter\": evaluate_model(X_train_corr_filtered, X_test_corr_filtered, y_train, y_test),\n",
        "    \"Low Variance Filter\": evaluate_model(X_train_low_var, X_test_low_var, y_train, y_test),\n",
        "    \"Forward Selection\": evaluate_model(X_train_forward_selected, X_test_forward_selected, y_train, y_test),\n",
        "    \"Backward Elimination\": evaluate_model(X_train_backward_selected, X_test_backward_selected, y_train, y_test),\n",
        "    \"Random Forest Selection\": evaluate_model(X_train_rf_selected, X_test_rf_selected, y_train, y_test)\n",
        "}\n",
        "\n",
        "for method, mse_value in results.items():\n",
        "    print(f\"{method}: MSE = {mse_value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F2vccDykmn0",
        "outputId": "4ced2e9a-1757-4c17-9c7d-6fee9923a395"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_rfe.py:291: UserWarning: Found n_features_to_select=5 > n_features=4. There will be no feature selection and all features will be kept.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_rfe.py:291: UserWarning: Found n_features_to_select=5 > n_features=4. There will be no feature selection and all features will be kept.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline (No Feature Selection): MSE = 143875373039.6255\n",
            "High Correlation Filter: MSE = 143875373039.6255\n",
            "Low Variance Filter: MSE = 143875373039.6255\n",
            "Forward Selection: MSE = 143875373039.6255\n",
            "Backward Elimination: MSE = 143875373039.6255\n",
            "Random Forest Selection: MSE = 147811757361.1377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wXY3CohrsJbS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}